---
title: "Assignment 4"
author: "Jasmin Capka"
date: "11/28/2021"
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
```

## Exercise 1

To create the plot of the posterior predictions of the Chimpanzee experiment on the bottom panel of Figure 11.4 on page 333, I decided to first understand the code for the plot in the top panel.
The following code is copied from chapter 11 of the book to be able to create the plots:

```{r preparation for plot, results = 'hide'}
# load data
data(chimpanzees)
d <- chimpanzees

# create treatment variable
d$treatment <- 1 + d$prosoc_left + 2 * d$condition

pl <- by(d$pulled_left, list(d$actor, d$treatment), mean)

# trimmed data list
dat_list <- list(
  pulled_left = d$pulled_left,
  actor = d$actor,
  treatment = as.integer(d$treatment)
)

# fit model
m11.4 <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data = dat_list,
  chains = 4,
  log_lik = TRUE
)
```

Then I took the code that was given to visualize the plot in the top panel and tried to understand it:

```{r plot in the top panel}
# create basis graph consisting of x and y axis 
plot(NULL, xlim = c(1, 28), ylim = c(0, 1), xlab = "",
     ylab = "proportion leftlever", xaxt = "n", yaxt = "n")

# define y axis
axis(2, at = c(0, 0.5, 1), labels = c(0, 0.5, 1))
# plot horizontal line at 0.5
abline(h = 0.5, lty = 2)

# divide the x-axis in 7 parts for 7 actors and label those
for (j in 1:7) abline(v = (j - 1) * 4 + 4.5, lwd = 0.5)
for (j in 1:7) text((j - 1) * 4 + 2.5, 1.1, concat("actor", j), xpd = TRUE)

# print two lines for each actor except the second one
for (j in(1:7)[-2]) {
  # takes the information about the lines from pl
  lines((j - 1) * 4 + c(1, 3), pl[j, c(1, 3)], lwd = 2, col = rangi2)
  lines((j - 1) * 4 + c(2, 4), pl[j, c(2, 4)], lwd = 2, col = rangi2)
}

# plots the points at the end of each of the lines (information from pl)
points(1:28, t(pl), pch = 16, col = "white", cex = 1.7)
points(1:28, t(pl), pch = c(1, 1, 16, 16), col = rangi2, lwd = 2)

# labels the first four points
yoff <- 0.01
text(1, pl[1, 1] - yoff, "R/N", pos = 1, cex = 0.8)
text(2, pl[1, 2] + yoff, "L/N", pos = 3, cex = 0.8)
text(3, pl[1, 3] - yoff, "R/P", pos = 1, cex = 0.8)
text(4, pl[1, 4] + yoff, "L/P", pos = 3, cex = 0.8)

# sets title of plot
mtext("observed proportions\n")
```

The following code was given to compute posterior function in the book. This is needed to create the plot on the bottom panel of Figure 11.4.

```{r}
dat <- list(actor = rep(1:7, each = 4), treatment = rep(1:4, times = 7))
p_post <- link(m11.4, data = dat)
p_mu <- apply(p_post, 2, mean)
p_ci <- apply(p_post, 2, PI)
```

Then I tried to adjust the code from the plot above:

* The first part that creates the axis and the separation for different actors was copied without adjustment.
* Then I changed the title to the title that was visible in the plot in the bottom panel.
* The values for the points and the lines in the upper plot were stored in the variable $pl$, which has a shape of (7, 4). For the posterior, all values are in $p\_mu$ which consists of one row with 28 values. Nevertheless, it follows the same logic as $pl$ when splitting those 28 values in 7 parts, containing 4 values each. Those 4 values in each part of $p\_mu$ can be treated the same as the 4 values in each of the 7 rows of $pl$ when plotting the posterior.
* Therefore, in order to draw the connecting lines, for each of the seven parts of $p\_mu$, the first and third value and the second and forth value are connected, following the logic of the upper plot, still without plotting them for actor 2.
* To draw the points the code from the to plot could be copied almost completely. Only $t(pl)$ was exchanged with $p\_mu$.
* Additionally, for all points and lines, the color setting to blue was removed to draw it in black.
* The last thing to add are the CI lines. The information about the CI intervals are stored in $p\_ci$, following a similar structure than $p\_mu$ only having two rows instead of one. Therefore, I adapted the for-loop of the connecting lines only this time including actor two. Then for each of the seven parts, we can split $p\_ci$ into, four CI lines are drawn. For each of the four columns, connecting the value from the first row with the one from the second row. The line width is set to the default value to make the lines a bit thinner as can be seen in the bottom plot of Figure 11.4.
* In the end I ordered the code to first draw the connecting lines, then the CI lines and in the end the points to achieve the same overlapping of those as in the given plot.

This is the result:

```{r}
# adopted as is
plot(NULL, xlim = c(1, 28), ylim = c(0, 1), xlab = "",
     ylab = "proportion leftlever", xaxt = "n", yaxt = "n")
axis(2, at = c(0, 0.5, 1), labels = c(0, 0.5, 1))
abline(h = 0.5, lty = 2)
for (j in 1:7) abline(v = (j - 1) * 4 + 4.5, lwd = 0.5)
for (j in 1:7) text((j - 1) * 4 + 2.5, 1.1, concat("actor", j), xpd = TRUE)

# change title
mtext("posterior predictions\n")

# draw connecting lines
for (j in(1:7)[-2]) {
  lines((j - 1) * 4 + c(1, 3), c(p_mu[j * 4 - 3], p_mu[j * 4 - 1]), lwd = 2)
  lines((j - 1) * 4 + c(2, 4), c(p_mu[j * 4 - 2], p_mu[j * 4 - 0]), lwd = 2)
}

# draw ci lines
for (j in(1:7)) {
  lines((j - 1) * 4 + c(1, 1), p_ci[c(1, 2), j * 4 - 3])
  lines((j - 1) * 4 + c(2, 2), p_ci[c(1, 2), j * 4 - 2])
  lines((j - 1) * 4 + c(3, 3), p_ci[c(1, 2), j * 4 - 1])
  lines((j - 1) * 4 + c(4, 4), p_ci[c(1, 2), j * 4 - 0])
}

# set points
points(1:28, p_mu, pch = 16, col = "white", cex = 1.7)
points(1:28, p_mu, pch = c(1, 1, 16, 16), lwd = 2)
```

## Exercise 2

First I imported the data:

```{r import data}
data(Wines2012)
d <- Wines2012
precis(d)
```

Then I took the provided code from the exercise to standardize and create IDs to distinguish between American and French judges and American and French wines:

```{r standardize and ids}
# standardize scores and create IDs for
# American / French judges and wines
dat_list <- list(
  S = standardize(d$score),
  jid = as.integer(d$judge),
  wid = as.integer(d$wine)
)
str(dat_list)
```

### Part 2.a)

*Side note*: I interpreted the exercise 2.a) in such a way, that I was already supposed to construct a linear regression model with quap. In hindsight, I realized that I might have been supposed to only do preparations under 2.a) and train the one ulam model. As I already did this quap model, I decided to leave it in. The ulam model can be found beneath at section 2.c).

I constructed a linear regression model with index variables. `judge` and `wine` in their representation as `jid` and `wid` are already index variables. Each judge and wine gets its individual parameter $\beta Ji[jid]$ or $\beta Wi[wid]$.

```{r quap model for judge and wine}
m2.1 <- quap(
  alist(
    S ~ dnorm(mu, sigma),
    mu <- bJi[jid] + bWi[wid],
    bJi[jid] ~ dnorm(0, 0.5),
    bWi[wid] ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = dat_list,
)
precis(m2.1, depth = 2)
```

As can be seen, there are 9 `judge` parameters and 20 `wine` parameters.

### Part 2.b)

I used the same priors for the parameters $\beta Ji[jid]$ and $\beta Wi[wid]$:

\[\beta Ji[jid] ∼ Normal(0, 0.5)\]
\[\beta Wi[wid] ∼ Normal(0, 0.5)\]

The score S is standardized with a mean of 0 and a standard deviation of 1, meaning 95% of values are between 2 and -2.
Therefore, I used normal distributions with a mean of 0 and a standard deviation of 0.5 as priors. This means when adding both, the mean values are added and the variances are added, resulting in a normal distribution with a mean of 0 and a standard deviation of 1. This is approximately the distribution of S.
Lokking at the sum of these priors, 95% of values are between 2 and -2. The density plot of the prior simulation can be seen below with the min and max value of the standardized score S represented by a green and red line respectively:

```{r}
N = 180

# define distribution of a and b
bJi <- rnorm(N, 0, 0.5)
bWi <- rnorm(N, 0, 0.5)

# sigma and mu
sample_sigma <- rexp(N, 1)
sample_mu <- bJi + bWi

# plot prior predictive simulation
prior_s <- rnorm(1e4, sample_mu, sample_sigma)
plot(density(prior_s))

# plot min and max line
abline(v = max(dat_list$S), col = 2)
abline(v = min(dat_list$S), col = 3)
```

I did not include an intercept $\alpha$ in the model as the mean value of the standardized score S is 0, which means that the intercept should be zero as well.

### Part 2.c)

This is the model with `ulam` instead of `quap`:

```{r ulam model for judge and wine, results = 'hide'}
m2.3 <- ulam(
  alist(
    S ~ dnorm(mu, sigma),
    mu <- bJi[jid] + bWi[wid],
    bJi[jid] ~ dnorm(0, 0.5),
    bWi[wid] ~ dnorm(0, 0.5),
    sigma ~ dexp(1)
  ),
  data = dat_list, chains = 4, cores = 4
)
```

```{r precis for model with judge and wine}
precis(m2.3, depth = 2)
```

### Part 2.d)

In order to check the chains for convergence, I use the `traceplot` and `trankplot` functions:

```{r trace and trankplots for m2.3}
traceplot(m2.3)
trankplot(m2.3)
```

In the traceplot, the four independent chains stick around the same region of high probability. In the trankplot, the histograms overlap and are within the same range. Therefore, the chains are converging. Another indicator for the convergence is that the Rhat values are all 1.

### Further questions:

To further inspect the implications of the parameters, I plotted them for both models:

```{r, fig.height = 20, fig.width = 10, out.width='70%'}
plot(coeftab(m2.1, m2.3))
```

One can directly see, that both models calculated almost identical posterior distributions.

Is there variation among individual judges and individual wines? Are there patterns you can notice just by plotting the differences?

* The parameters $\beta Ji[jid]$ explain the average influence of the individual judges on the scores of the wines. This means, judges with lower parameter values distribute on average lower scores, the ones with higher parameter values judge the wines on average with higher scores. Looking at the graph above, I definitely see variations in the $\beta Ji[jid]$ parameters and I am able to tell some of the judges apart as well.
* The parameters $\beta Wi[wid]$ indicate the average individual score of the wines across all judges. These parameters vary only a bit. Wine 18 has a uniquely identifiable parameter distribution, but other than that, the wines cannot easily be told apart.

Which judges have the lowest and highest ratings? Which wines are rated worst and which best on average?

* Looking at the mean values for the parameters $\alpha[jid]$ and at the plot, judge 8 gave on average the lowest ratings followed by judge 4 and judge 5 gave the highest ratings followed by judge 6. Looking at all judges, judge 1 and 9 still gave on average scores slightly below the average score, whereas judges 2, 3, and 7 gave on average scores slightly above the average score.
* Comparing the same for the parameters $\beta[wid]$, wine 18 had the lowest ratings. As the other wines do not vary that much, wine 4 had the highest average ratings, closely followed by and wine 20 and others.

# Excercise 3

First, I created indicator variables containing values of 0 and 1 for `flight`, `wine.amer` and `judge.amer`:

```{r list of data}
dat_list <- list(
  S = standardize(d$score),
  R = ifelse(d$flight == "red ", 1L, 0L),
  WA = as.integer(d$wine.amer),
  JA = as.integer(d$judge.amer)
)
str(dat_list)
```

Then I used `ulam` to compute the posterior distribution and analyze the effects of `R` (flight), `WA` (wine.amer) and `JA` (judge.amer) on `S`:

```{r ulam model with indicator variables, results = 'hide'}
m3 <- ulam(
  alist(
    S ~ dnorm(mu, sigma),
    mu <- a + bR * R + bW * WA + bJ * JA,
    a ~ dnorm(0, 0.5),
    bR ~ dnorm(0, 0.33),
    bW ~ dnorm(0, 0.33),
    bJ ~ dnorm(0, 0.33),
    sigma ~ dexp(1)
  ),
  data = dat_list, chains = 4, cores = 4
)
```

```{r precis for ulam model with indicator variables}
precis(m3, depth = 2)
```

For the same reasons as in Exercise 2, I picked normal distributions with a mean of 0, but a standard deviation of 0.33 for the parameters `bR`, `bW` and `bJ`, . This is because we now have three indicator variables that are able to build the score. I gave each the same share of the standard deviation of the score, because I did not have any more information about their impact.
This time I also included an intercept $\alpha$ to check its influence. I gave it a mean value of 0 and a standard deviation of 0.5 to be able to span across the entire range of standardized score values.

In order to check the chains for convergence, I use the `traceplot` and `trankplot` functions again:

```{r trace and trankplots for m3}
traceplot(m3)
trankplot(m3)
```

The outcomes are similar to the plots for m2.3:
In the traceplot, the four independent chains stick around the same region of high probability. In the trankplot, the histograms overlap and are within the same range. Therefore, the chains are converging. Another indicator for the convergence is that the Rhat values are all 1.

To further analyze the parameters, I plotted them:

```{r}
plot(precis(m3, depth=2))
```

The intercept $\alpha$ is distributed on both sides of zero, having a mean close to zero. This means, as already expected in Exercise 2, $\alpha$ has no significant influence on the standardized score.

What do you conclude about the differences among the wines and judges?

* The parameter `bR` has a mean close to zero and a high standard deviation, spreading from values below to values above zero. This means that on average red and white wines are scored the same. Therefore, the flight of a wine has no significant influence on the average score a wine receives.
* The parameter `bW` is mostly below zero. This means that on average French wines receive better scores than American wines.
* The parameter `bJ` is slightly above zero. This means that on average American judges tend to give wines higher scores than French judges.

Compare your results to the results from Problem 2.

* Comparing the models in general, the model from exercise 2 tries to display the effects of individual judges and individual wines on the average score, whereas the model from exercise 3 tries to display the effects of features of those wines and judges on the average score.
* Additionally, it is possible to compare the actual results with each other. In order to do that I tried to derive the specific features for judges that give high/low scores on average and wines that get high/low scores on average from exercise 2:

```{r}
wine <- levels(d$wine)
judge <- levels(d$judge)

# get row for wines
print("Wine 18:")
d[which(d$wine == wine[18]), ][1, ]
print("Wine 4:")
d[which(d$wine == wine[4]), ][1, ]
print("Wine 20:")
d[which(d$wine == wine[20]), ][1, ]

# get row for judges
print("Judge 8:")
d[which(d$judge == judge[8]), ][1, ]
print("Judge 4:")
d[which(d$judge == judge[4]), ][1, ]
print("Judge 5:")
d[which(d$judge == judge[5]), ][1, ]
print("Judge 6:")
d[which(d$judge == judge[6]), ][1, ]
```

* The result from exercise 3 was, that on average French wines receive better scores than American wines. Looking at the worst performing wine from exercise 2, which was wine 18, it is actually an american wine. The wines with high ratings, wine 4 and wine 20 are both french wines. Therefore, the conclusions of both exercises match.
* The second result from exercise 3 was, that on average American judges tend to give wines higher scores than French judges. Comparing this with the results form exercise 2, the judges 5 and 6 gave the highest ratings and are both American. The judges 8 and 4 gave the worst ratings. Judge 4 is actually a French judge, but judge 8 is a American one. Nevertheless, as all conclusions are about average tendencies, the conclusions of both exercises still match.
